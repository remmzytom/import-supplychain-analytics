{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05553485",
   "metadata": {},
   "source": [
    "# Imports Data Cleaning Notebook\n",
    "\n",
    "This notebook performs comprehensive data cleaning on the ABS imports dataset for 2024-2025.\n",
    "\n",
    "## Cleaning Steps:\n",
    "1. Load and inspect the raw data\n",
    "2. Handle missing values\n",
    "3. Convert data types\n",
    "4. Standardize text fields\n",
    "5. Handle outliers and invalid values\n",
    "6. Create derived features\n",
    "7. Remove duplicates\n",
    "8. Save cleaned dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "463ff55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Pandas version: 2.1.4\n",
      "NumPy version: 1.26.4\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f177f7ec",
   "metadata": {},
   "source": [
    "## 1. Load and Inspect Raw Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7fc224b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Data loaded successfully!\n",
      "Shape: 4,481,579 rows × 18 columns\n",
      "\n",
      "Column names:\n",
      "['month', 'mode', 'mode_description', 'commodity_code', 'commodity_description', 'ausport_code', 'ausport_description', 'osport_code', 'osport_description', 'state', 'country_code', 'country_description', 'weight', 'valuefob', 'valuecif', 'unit_quantity', 'quantity', 'year']\n"
     ]
    }
   ],
   "source": [
    "# Load the raw imports data\n",
    "data_path = 'data/imports_2024_2025.csv'\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "print(f\"\\n Data loaded successfully!\")\n",
    "print(f\"Shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "print(f\"\\nColumn names:\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c42a058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATASET OVERVIEW ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>mode</th>\n",
       "      <th>mode_description</th>\n",
       "      <th>commodity_code</th>\n",
       "      <th>commodity_description</th>\n",
       "      <th>ausport_code</th>\n",
       "      <th>ausport_description</th>\n",
       "      <th>osport_code</th>\n",
       "      <th>osport_description</th>\n",
       "      <th>state</th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_description</th>\n",
       "      <th>weight</th>\n",
       "      <th>valuefob</th>\n",
       "      <th>valuecif</th>\n",
       "      <th>unit_quantity</th>\n",
       "      <th>quantity</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>January 2024</td>\n",
       "      <td>A</td>\n",
       "      <td>AIR</td>\n",
       "      <td>79391</td>\n",
       "      <td>Rafts, inflatable</td>\n",
       "      <td>101</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>840460</td>\n",
       "      <td>Honolulu</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>USA</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1204.37</td>\n",
       "      <td>1244.67</td>\n",
       "      <td>Number</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>January 2024</td>\n",
       "      <td>S</td>\n",
       "      <td>SEA</td>\n",
       "      <td>7528</td>\n",
       "      <td>Saffron</td>\n",
       "      <td>101</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>840468</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>SPAI</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58646.15</td>\n",
       "      <td>60840.25</td>\n",
       "      <td>Kilograms</td>\n",
       "      <td>416.40</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>January 2024</td>\n",
       "      <td>A</td>\n",
       "      <td>AIR</td>\n",
       "      <td>69940</td>\n",
       "      <td>Springs and leaves for springs, of iron or steel</td>\n",
       "      <td>101</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>276150</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>FGMY</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4997.11</td>\n",
       "      <td>5094.51</td>\n",
       "      <td>Number</td>\n",
       "      <td>1204.00</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>January 2024</td>\n",
       "      <td>A</td>\n",
       "      <td>AIR</td>\n",
       "      <td>74831</td>\n",
       "      <td>Articulated link roller chain of iron or steel</td>\n",
       "      <td>523</td>\n",
       "      <td>Perth</td>\n",
       "      <td>528050</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>JAP</td>\n",
       "      <td>Japan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3343.30</td>\n",
       "      <td>3468.06</td>\n",
       "      <td>Kilograms</td>\n",
       "      <td>103.73</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>January 2024</td>\n",
       "      <td>S</td>\n",
       "      <td>SEA</td>\n",
       "      <td>82116</td>\n",
       "      <td>Wooden framed seats, nes</td>\n",
       "      <td>401</td>\n",
       "      <td>Port Adelaide</td>\n",
       "      <td>276450</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>FGMY</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15122.99</td>\n",
       "      <td>15779.34</td>\n",
       "      <td>Number</td>\n",
       "      <td>43.00</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          month mode mode_description  commodity_code  \\\n",
       "0  January 2024    A              AIR           79391   \n",
       "1  January 2024    S              SEA            7528   \n",
       "2  January 2024    A              AIR           69940   \n",
       "3  January 2024    A              AIR           74831   \n",
       "4  January 2024    S              SEA           82116   \n",
       "\n",
       "                              commodity_description  ausport_code  \\\n",
       "0                                 Rafts, inflatable           101   \n",
       "1                                           Saffron           101   \n",
       "2  Springs and leaves for springs, of iron or steel           101   \n",
       "3    Articulated link roller chain of iron or steel           523   \n",
       "4                          Wooden framed seats, nes           401   \n",
       "\n",
       "  ausport_description  osport_code osport_description              state  \\\n",
       "0              Sydney       840460           Honolulu    New South Wales   \n",
       "1              Sydney       840468        Los Angeles    New South Wales   \n",
       "2              Sydney       276150          Frankfurt           Victoria   \n",
       "3               Perth       528050          Amsterdam  Western Australia   \n",
       "4       Port Adelaide       276450            Hamburg    South Australia   \n",
       "\n",
       "  country_code       country_description  weight  valuefob  valuecif  \\\n",
       "0          USA  United States of America     0.0   1204.37   1244.67   \n",
       "1         SPAI                     Spain     0.0  58646.15  60840.25   \n",
       "2         FGMY                   Germany     0.0   4997.11   5094.51   \n",
       "3          JAP                     Japan     0.0   3343.30   3468.06   \n",
       "4         FGMY                   Germany     0.0  15122.99  15779.34   \n",
       "\n",
       "  unit_quantity  quantity  year  \n",
       "0        Number      2.00  2024  \n",
       "1     Kilograms    416.40  2024  \n",
       "2        Number   1204.00  2024  \n",
       "3     Kilograms    103.73  2024  \n",
       "4        Number     43.00  2024  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"=== DATASET OVERVIEW ===\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9eaa467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA TYPES & MISSING VALUES ===\n",
      "\n",
      "Data types:\n",
      "month                     object\n",
      "mode                      object\n",
      "mode_description          object\n",
      "commodity_code             int64\n",
      "commodity_description     object\n",
      "ausport_code               int64\n",
      "ausport_description       object\n",
      "osport_code                int64\n",
      "osport_description        object\n",
      "state                     object\n",
      "country_code              object\n",
      "country_description       object\n",
      "weight                   float64\n",
      "valuefob                 float64\n",
      "valuecif                 float64\n",
      "unit_quantity             object\n",
      "quantity                 float64\n",
      "year                       int64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "Missing values:\n",
      "No missing values found!\n"
     ]
    }
   ],
   "source": [
    "# Check data types and missing values\n",
    "print(\"=== DATA TYPES & MISSING VALUES ===\")\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\n\\nMissing values:\")\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Missing Percentage': missing_pct\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "if len(missing_df) > 0:\n",
    "    print(missing_df)\n",
    "else:\n",
    "    print(\"No missing values found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "800e8cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DUPLICATE CHECK ===\n",
      "Duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "print(\"=== DUPLICATE CHECK ===\")\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(f\"Duplicate rows: {duplicate_count:,}\")\n",
    "if duplicate_count > 0:\n",
    "    print(f\"Percentage: {(duplicate_count / len(df)) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f648e22d",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning and Conversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de5106a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STARTING DATA CLEANING ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a copy for cleaning\n",
    "df_clean = df.copy()\n",
    "print(\"=== STARTING DATA CLEANING ===\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b68db992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardizing column names...\n",
      "Column names standardized\n",
      "New columns: ['month', 'mode', 'mode_description', 'commodity_code', 'commodity_description', 'ausport_code', 'ausport_description', 'osport_code', 'osport_description', 'state', 'country_code', 'country_description', 'weight', 'valuefob', 'valuecif', 'unit_quantity', 'quantity', 'year']\n"
     ]
    }
   ],
   "source": [
    "# Standardize column names (convert to lowercase with underscores for consistency)\n",
    "print(\"Standardizing column names...\")\n",
    "df_clean.columns = df_clean.columns.str.lower().str.replace(' ', '_')\n",
    "print(f\"Column names standardized\")\n",
    "print(f\"New columns: {df_clean.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c2563c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CONVERTING NUMERIC COLUMNS ===\n",
      "\n",
      "Processing weight...\n",
      "  Negative values found: 22,151\n",
      "  Min: 0.00, Max: 530,451.00, Mean: 44.62\n",
      "\n",
      "Processing valuefob...\n",
      "  Negative values found: 36,030\n",
      "  Min: 0.00, Max: 2,923,069,554.39, Mean: 178,885.61\n",
      "\n",
      "Processing valuecif...\n",
      "  Negative values found: 36,030\n",
      "  Min: 0.00, Max: 2,939,111,352.40, Mean: 186,456.17\n",
      "\n",
      "Processing quantity...\n",
      "  Min: 0.00, Max: 789,189,365.00, Mean: 44,881.26\n",
      "\n",
      " Numeric columns processed\n"
     ]
    }
   ],
   "source": [
    "# Convert numeric columns and handle missing values\n",
    "print(\"\\n=== CONVERTING NUMERIC COLUMNS ===\")\n",
    "\n",
    "# Numeric columns in imports data\n",
    "numeric_columns = ['weight', 'valuefob', 'valuecif', 'quantity']\n",
    "\n",
    "for col in numeric_columns:\n",
    "    if col in df_clean.columns:\n",
    "        print(f\"\\nProcessing {col}...\")\n",
    "        \n",
    "        # Convert to numeric\n",
    "        df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "        \n",
    "        # Check missing values\n",
    "        missing_count = df_clean[col].isnull().sum()\n",
    "        if missing_count > 0:\n",
    "            print(f\"  Missing values: {missing_count:,} ({(missing_count/len(df_clean))*100:.2f}%)\")\n",
    "            # Fill missing with 0 for trade data\n",
    "            df_clean[col] = df_clean[col].fillna(0)\n",
    "        \n",
    "        # Handle negative values (shouldn't exist in trade data)\n",
    "        negative_count = (df_clean[col] < 0).sum()\n",
    "        if negative_count > 0:\n",
    "            print(f\"  Negative values found: {negative_count:,}\")\n",
    "            df_clean[col] = df_clean[col].clip(lower=0)\n",
    "        \n",
    "        # Show summary statistics\n",
    "        print(f\"  Min: {df_clean[col].min():,.2f}, Max: {df_clean[col].max():,.2f}, Mean: {df_clean[col].mean():,.2f}\")\n",
    "\n",
    "print(\"\\n Numeric columns processed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52d2b4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CLEANING TEXT COLUMNS ===\n",
      "\n",
      "Processing country_description...\n",
      "  Unique values: 224\n",
      "\n",
      "Processing commodity_description...\n",
      "  Unique values: 2,897\n",
      "\n",
      "Processing mode_description...\n",
      "  Unique values: 4\n",
      "\n",
      "Processing ausport_description...\n",
      "  Unique values: 61\n",
      "\n",
      "Processing osport_description...\n",
      "  Unique values: 590\n",
      "\n",
      "Processing state...\n",
      "  Unique values: 9\n",
      "\n",
      "Processing unit_quantity...\n",
      "  Unique values: 16\n",
      "\n",
      "Text columns cleaned\n"
     ]
    }
   ],
   "source": [
    "# Clean text columns\n",
    "print(\"\\n=== CLEANING TEXT COLUMNS ===\")\n",
    "\n",
    "# Text columns that should be standardized\n",
    "text_columns = ['country_description', 'commodity_description', 'mode_description', \n",
    "                'ausport_description', 'osport_description', 'state', 'unit_quantity']\n",
    "\n",
    "for col in text_columns:\n",
    "    if col in df_clean.columns:\n",
    "        print(f\"\\nProcessing {col}...\")\n",
    "        \n",
    "        # Convert to string and handle missing values\n",
    "        df_clean[col] = df_clean[col].astype(str)\n",
    "        \n",
    "        # Replace 'nan' strings and actual NaN with 'Unknown'\n",
    "        df_clean[col] = df_clean[col].replace({'nan': 'Unknown', 'NaN': 'Unknown', 'None': 'Unknown'})\n",
    "        df_clean[col] = df_clean[col].fillna('Unknown')\n",
    "        \n",
    "        # Clean whitespace\n",
    "        df_clean[col] = df_clean[col].str.strip()\n",
    "        df_clean[col] = df_clean[col].str.replace(r'\\s+', ' ', regex=True)  # Multiple spaces to single\n",
    "        df_clean[col] = df_clean[col].str.replace(r'[\\n\\r\\t]+', ' ', regex=True)  # Remove newlines/tabs\n",
    "        \n",
    "        # Remove quotes\n",
    "        df_clean[col] = df_clean[col].str.replace('\"', '', regex=False)\n",
    "        df_clean[col] = df_clean[col].str.replace(\"'\", '', regex=False)\n",
    "        \n",
    "        # Count unique values\n",
    "        unique_count = df_clean[col].nunique()\n",
    "        print(f\"  Unique values: {unique_count:,}\")\n",
    "\n",
    "print(\"\\nText columns cleaned\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85eb70a",
   "metadata": {},
   "source": [
    "## 2.5. Unit Validation and Standardization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a019c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STANDARDIZING UNIT NAMES ===\n",
      "Checking for unit name variations...\n",
      "Unique unit types before standardization: 16\n",
      " Standardized 11,691 unit names\n",
      "\n",
      "Changes made:\n",
      "unit_quantity_original  unit_quantity\n",
      "Litres Al               Litres           11691\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique unit types after standardization: 15\n"
     ]
    }
   ],
   "source": [
    "# Standardize unit_quantity names\n",
    "print(\"\\n=== STANDARDIZING UNIT NAMES ===\")\n",
    "\n",
    "# Create unit standardization mapping\n",
    "unit_mapping = {\n",
    "    'Litres Al': 'Litres',  # Standardize variation\n",
    "    'litres al': 'Litres',\n",
    "    'LITRES AL': 'Litres',\n",
    "    # Add other variations if found\n",
    "}\n",
    "\n",
    "# Check for other potential variations\n",
    "print(\"Checking for unit name variations...\")\n",
    "original_units = df_clean['unit_quantity'].value_counts()\n",
    "print(f\"Unique unit types before standardization: {len(original_units)}\")\n",
    "\n",
    "# Apply standardization\n",
    "before_count = len(df_clean)\n",
    "df_clean['unit_quantity_original'] = df_clean['unit_quantity'].copy()  # Keep original for reference\n",
    "df_clean['unit_quantity'] = df_clean['unit_quantity'].map(unit_mapping).fillna(df_clean['unit_quantity'])\n",
    "\n",
    "# Check what changed\n",
    "changed = (df_clean['unit_quantity_original'] != df_clean['unit_quantity']).sum()\n",
    "if changed > 0:\n",
    "    print(f\" Standardized {changed:,} unit names\")\n",
    "    print(\"\\nChanges made:\")\n",
    "    changes = df_clean[df_clean['unit_quantity_original'] != df_clean['unit_quantity']][['unit_quantity_original', 'unit_quantity']].value_counts()\n",
    "    print(changes)\n",
    "else:\n",
    "    print(\"No unit name variations found to standardize\")\n",
    "\n",
    "print(f\"\\nUnique unit types after standardization: {df_clean['unit_quantity'].nunique()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d998539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ROUNDING NUMBER UNIT QUANTITIES ===\n",
      "Found 6,353 'Number' records with decimal quantities\n",
      "  Percentage: 0.34%\n",
      "\n",
      "  Examples before rounding:\n",
      "unit_quantity  quantity                               commodity_description\n",
      "       Number   4142.32                                   Base metal hinges\n",
      "       Number 248633.95                                Razors, non-electric\n",
      "       Number    157.66  Intake air filters for internal combustion engines\n",
      "       Number    118.46 Valves for oleohydraulic or pneumatic transmissions\n",
      "       Number  11660.41                                    Printed circuits\n",
      "\n",
      " Rounded 6,353 'Number' quantities to integers\n",
      "Verification: All 'Number' quantities are now integers\n"
     ]
    }
   ],
   "source": [
    "# Round \"Number\" unit quantities to integers\n",
    "print(\"\\n=== ROUNDING NUMBER UNIT QUANTITIES ===\")\n",
    "\n",
    "# Find Number units with decimals\n",
    "number_mask = df_clean['unit_quantity'] == 'Number'\n",
    "if number_mask.any():\n",
    "    number_data = df_clean[number_mask].copy()\n",
    "    quantities = pd.to_numeric(number_data['quantity'], errors='coerce')\n",
    "    \n",
    "    # Find records with decimals\n",
    "    has_decimals = (quantities % 1 != 0) & (~quantities.isna())\n",
    "    decimal_count = has_decimals.sum()\n",
    "    \n",
    "    if decimal_count > 0:\n",
    "        print(f\"Found {decimal_count:,} 'Number' records with decimal quantities\")\n",
    "        print(f\"  Percentage: {(decimal_count/number_mask.sum())*100:.2f}%\")\n",
    "        \n",
    "        # Show examples before rounding\n",
    "        print(\"\\n  Examples before rounding:\")\n",
    "        examples = df_clean.loc[number_mask & has_decimals, ['unit_quantity', 'quantity', 'commodity_description']].head(5)\n",
    "        print(examples.to_string(index=False))\n",
    "        \n",
    "        # Round to nearest integer\n",
    "        df_clean.loc[number_mask, 'quantity'] = pd.to_numeric(df_clean.loc[number_mask, 'quantity'], errors='coerce').round(0)\n",
    "        \n",
    "        print(f\"\\n Rounded {decimal_count:,} 'Number' quantities to integers\")\n",
    "        \n",
    "        # Verify\n",
    "        quantities_after = pd.to_numeric(df_clean.loc[number_mask, 'quantity'], errors='coerce')\n",
    "        still_decimal = (quantities_after % 1 != 0).sum()\n",
    "        if still_decimal == 0:\n",
    "            print(\"Verification: All 'Number' quantities are now integers\")\n",
    "        else:\n",
    "            print(f\" Warning: {still_decimal} 'Number' quantities still have decimals\")\n",
    "    else:\n",
    "        print(\"No 'Number' units with decimals found\")\n",
    "else:\n",
    "    print(\"No 'Number' units found in dataset\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24d8aa7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== WEIGHT UNIT VALIDATION ===\n",
      "Weight statistics:\n",
      "  Min: 0.00 tonnes\n",
      "  Max: 530,451.00 tonnes\n",
      "  Mean: 44.62 tonnes\n",
      "  Median: 0.01 tonnes\n",
      "\n",
      "Weight distribution:\n",
      "  Weights < 1 tonne: 3,439,041 (76.74%)\n",
      "  Weights < 0.1 tonne: 2,840,135 (63.37%)\n",
      "  Weights > 1000 tonnes: 13,669 (0.31%)\n",
      "\n",
      " Weight validation completed (assuming all weights are in tonnes)\n",
      "   Note: Small weights (< 1 tonne) are normal for small shipments\n"
     ]
    }
   ],
   "source": [
    "# Validate weight units (assuming tonnes, just verify consistency)\n",
    "print(\"\\n=== WEIGHT UNIT VALIDATION ===\")\n",
    "\n",
    "weights = pd.to_numeric(df_clean['weight'], errors='coerce')\n",
    "\n",
    "print(f\"Weight statistics:\")\n",
    "print(f\"  Min: {weights.min():,.2f} tonnes\")\n",
    "print(f\"  Max: {weights.max():,.2f} tonnes\")\n",
    "print(f\"  Mean: {weights.mean():,.2f} tonnes\")\n",
    "print(f\"  Median: {weights.median():,.2f} tonnes\")\n",
    "\n",
    "# Check distribution\n",
    "small_weights = (weights < 1).sum()\n",
    "very_small_weights = (weights < 0.1).sum()\n",
    "large_weights = (weights > 1000).sum()\n",
    "\n",
    "print(f\"\\nWeight distribution:\")\n",
    "print(f\"  Weights < 1 tonne: {small_weights:,} ({(small_weights/len(df_clean))*100:.2f}%)\")\n",
    "print(f\"  Weights < 0.1 tonne: {very_small_weights:,} ({(very_small_weights/len(df_clean))*100:.2f}%)\")\n",
    "print(f\"  Weights > 1000 tonnes: {large_weights:,} ({(large_weights/len(df_clean))*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n Weight validation completed (assuming all weights are in tonnes)\")\n",
    "print(\"   Note: Small weights (< 1 tonne) are normal for small shipments\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d85afec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PROCESSING DATE INFORMATION ===\n",
      "  Years in dataset: [2024, 2025]\n",
      "  Month column now contains: ['January', 'February', 'May', 'March', 'April']...\n",
      "  Month numbers range: 1 to 12\n",
      "\n",
      "✅ Date information processed\n"
     ]
    }
   ],
   "source": [
    "# Clean month column - extract month name only (remove year since year column exists)\n",
    "print(\"\\n=== PROCESSING DATE INFORMATION ===\")\n",
    "\n",
    "if 'month' in df_clean.columns:\n",
    "    # Ensure month is string\n",
    "    df_clean['month'] = df_clean['month'].astype(str)\n",
    "    \n",
    "    # Extract month name only (remove year part) since year column already exists\n",
    "    # Extract just the month name from \"January 2024\" -> \"January\"\n",
    "    month_name = df_clean['month'].str.extract(r'^([A-Za-z]+)')[0]\n",
    "    df_clean['month'] = month_name  # Replace month column with just month name\n",
    "    \n",
    "    # Create month number for analysis\n",
    "    month_map = {\n",
    "        'January': 1, 'February': 2, 'March': 3, 'April': 4,\n",
    "        'May': 5, 'June': 6, 'July': 7, 'August': 8,\n",
    "        'September': 9, 'October': 10, 'November': 11, 'December': 12\n",
    "    }\n",
    "    \n",
    "    df_clean['month_number'] = df_clean['month'].map(month_map)\n",
    "    \n",
    "    # Verify year column exists (should already be present)\n",
    "    if 'year' in df_clean.columns:\n",
    "        print(f\"  Years in dataset: {sorted(df_clean['year'].dropna().unique().tolist())}\")\n",
    "    else:\n",
    "        print(\"  ⚠️  Warning: Year column not found\")\n",
    "    \n",
    "    print(f\"  Month column now contains: {df_clean['month'].unique()[:5].tolist()}...\")\n",
    "    print(f\"  Month numbers range: {df_clean['month_number'].min()} to {df_clean['month_number'].max()}\")\n",
    "\n",
    "print(\"\\n✅ Date information processed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc6b1f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CREATING DERIVED FEATURES ===\n",
      "  Created: value_per_tonne_fob\n",
      "  Created: value_per_tonne_cif\n",
      "  Created: insurance_freight_cost\n",
      "\n",
      "Derived features created\n"
     ]
    }
   ],
   "source": [
    "# Create derived features\n",
    "print(\"\\n=== CREATING DERIVED FEATURES ===\")\n",
    "\n",
    "# Calculate value per tonne (using weight)\n",
    "if 'valuefob' in df_clean.columns and 'weight' in df_clean.columns:\n",
    "    # Convert weight to tonnes if needed (assuming weight is in tonnes already)\n",
    "    denominator = df_clean['weight'].replace(0, np.nan)\n",
    "    df_clean['value_per_tonne_fob'] = df_clean['valuefob'] / denominator\n",
    "    print(\"  Created: value_per_tonne_fob\")\n",
    "\n",
    "if 'valuecif' in df_clean.columns and 'weight' in df_clean.columns:\n",
    "    denominator = df_clean['weight'].replace(0, np.nan)\n",
    "    df_clean['value_per_tonne_cif'] = df_clean['valuecif'] / denominator\n",
    "    print(\"  Created: value_per_tonne_cif\")\n",
    "\n",
    "# Calculate difference between CIF and FOB (insurance and freight costs)\n",
    "if 'valuecif' in df_clean.columns and 'valuefob' in df_clean.columns:\n",
    "    df_clean['insurance_freight_cost'] = df_clean['valuecif'] - df_clean['valuefob']\n",
    "    df_clean['insurance_freight_cost'] = df_clean['insurance_freight_cost'].clip(lower=0)  # Shouldn't be negative\n",
    "    print(\"  Created: insurance_freight_cost\")\n",
    "\n",
    "# Add processing date\n",
    "#df_clean['data_processed_date'] = datetime.now().strftime('%Y-%m-%d')\n",
    "#print(\"  Created: data_processed_date\")\n",
    "\n",
    "print(\"\\nDerived features created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "651f65b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== REMOVING DUPLICATES ===\n",
      "  Before: 4,481,579 rows\n",
      "  After: 4,481,579 rows\n",
      "  Removed: 0 duplicate rows (0.00%)\n",
      "\n",
      " Duplicates removed\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "print(\"\\n=== REMOVING DUPLICATES ===\")\n",
    "before_count = len(df_clean)\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "after_count = len(df_clean)\n",
    "removed = before_count - after_count\n",
    "\n",
    "print(f\"  Before: {before_count:,} rows\")\n",
    "print(f\"  After: {after_count:,} rows\")\n",
    "print(f\"  Removed: {removed:,} duplicate rows ({(removed/before_count)*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n Duplicates removed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705c6a1d",
   "metadata": {},
   "source": [
    "## 3. Data Quality Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ab1ca79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINAL DATA QUALITY SUMMARY ===\n",
      "\n",
      "Total rows: 4,481,579\n",
      "Total columns: 23\n",
      "\n",
      "Data types:\n",
      "object     11\n",
      "float64     7\n",
      "int64       5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values (after cleaning):\n",
      "                     Missing Count  Percentage\n",
      "value_per_tonne_fob        1823199   40.682068\n",
      "value_per_tonne_cif        1823199   40.682068\n",
      "\n",
      "Summary statistics for numeric columns:\n",
      "       commodity_code  ausport_code   osport_code        weight      valuefob  \\\n",
      "count    4.481579e+06  4.481579e+06  4.481579e+06  4.481579e+06  4.481579e+06   \n",
      "mean     7.137245e+04  2.463182e+02  4.889941e+05  4.461985e+01  1.788856e+05   \n",
      "std      1.896213e+04  1.965422e+02  2.711864e+05  1.471221e+03  3.747555e+06   \n",
      "min      1.500000e+02  1.010000e+02  4.399000e+03  0.000000e+00  0.000000e+00   \n",
      "25%      6.661300e+04  1.010000e+02  2.504540e+05  0.000000e+00  2.711180e+03   \n",
      "50%      7.478000e+04  2.010000e+02  4.580110e+05  9.500000e-03  9.085290e+03   \n",
      "75%      8.311200e+04  3.010000e+02  7.640030e+05  6.970000e-01  4.269810e+04   \n",
      "max      9.999900e+04  9.990000e+02  9.999990e+05  5.304510e+05  2.923070e+09   \n",
      "\n",
      "           valuecif      quantity          year  month_number  \\\n",
      "count  4.481579e+06  4.481579e+06  4.481579e+06  4.481579e+06   \n",
      "mean   1.864562e+05  4.488126e+04  2.024401e+03  5.778312e+00   \n",
      "std    3.812089e+06  1.782612e+06  4.901071e-01  3.186650e+00   \n",
      "min    0.000000e+00  0.000000e+00  2.024000e+03  1.000000e+00   \n",
      "25%    2.982830e+03  0.000000e+00  2.024000e+03  3.000000e+00   \n",
      "50%    9.836390e+03  5.000000e+00  2.024000e+03  6.000000e+00   \n",
      "75%    4.551440e+04  2.690000e+02  2.025000e+03  8.000000e+00   \n",
      "max    2.939111e+09  7.891894e+08  2.025000e+03  1.200000e+01   \n",
      "\n",
      "       value_per_tonne_fob  value_per_tonne_cif  insurance_freight_cost  \n",
      "count         2.658380e+06         2.658380e+06            4.481579e+06  \n",
      "mean          1.209390e+06         1.239101e+06            7.570568e+03  \n",
      "std           3.803193e+07         3.819694e+07            1.033281e+05  \n",
      "min           6.828052e-02         6.978292e-02            0.000000e+00  \n",
      "25%           8.772747e+03         9.642984e+03            1.422400e+02  \n",
      "50%           4.932992e+04         5.672506e+04            4.983500e+02  \n",
      "75%           3.033090e+05         3.266113e+05            2.184830e+03  \n",
      "max           2.916887e+10         2.916942e+10            2.648488e+07  \n"
     ]
    }
   ],
   "source": [
    "# Final data quality check\n",
    "print(\"=== FINAL DATA QUALITY SUMMARY ===\\n\")\n",
    "\n",
    "print(f\"Total rows: {len(df_clean):,}\")\n",
    "print(f\"Total columns: {len(df_clean.columns)}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(df_clean.dtypes.value_counts())\n",
    "\n",
    "print(f\"\\nMissing values (after cleaning):\")\n",
    "final_missing = df_clean.isnull().sum()\n",
    "final_missing_df = pd.DataFrame({\n",
    "    'Missing Count': final_missing,\n",
    "    'Percentage': (final_missing / len(df_clean)) * 100\n",
    "})\n",
    "final_missing_df = final_missing_df[final_missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "if len(final_missing_df) > 0:\n",
    "    print(final_missing_df)\n",
    "else:\n",
    "    print(\"✅ No missing values!\")\n",
    "\n",
    "print(f\"\\nSummary statistics for numeric columns:\")\n",
    "numeric_cols = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if numeric_cols:\n",
    "    print(df_clean[numeric_cols].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c52c9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DATA BREAKDOWN ===\n",
      "\n",
      "Records by year:\n",
      "  2024: 2,684,331 records\n",
      "  2025: 1,797,248 records\n",
      "\n",
      "Records by transport mode:\n",
      "  SEA: 2,283,382 records\n",
      "  AIR: 2,193,846 records\n",
      "  POST: 4,311 records\n",
      "  MODE OF TRANSPORT NOT AVAILABLE FOR PUBLICATION: 40 records\n",
      "\n",
      "Top 10 countries by record count:\n",
      "  China (excludes SARs and Taiwan): 931,539 records\n",
      "  United States of America: 536,656 records\n",
      "  Germany: 310,477 records\n",
      "  Italy (includes Holy See and San Marino): 237,254 records\n",
      "  India: 174,615 records\n",
      "  Japan: 173,761 records\n",
      "  United Kingdom, Channel Islands and Isle of Man, nfd: 170,358 records\n",
      "  France (includes Andorra and Monaco): 127,275 records\n",
      "  Taiwan: 119,187 records\n",
      "  Vietnam: 103,872 records\n"
     ]
    }
   ],
   "source": [
    "# Show breakdown by key dimensions\n",
    "print(\"\\n=== DATA BREAKDOWN ===\")\n",
    "\n",
    "if 'year' in df_clean.columns:\n",
    "    print(\"\\nRecords by year:\")\n",
    "    year_counts = df_clean['year'].value_counts().sort_index()\n",
    "    for year, count in year_counts.items():\n",
    "        print(f\"  {year}: {count:,} records\")\n",
    "\n",
    "if 'mode_description' in df_clean.columns:\n",
    "    print(\"\\nRecords by transport mode:\")\n",
    "    mode_counts = df_clean['mode_description'].value_counts()\n",
    "    for mode, count in mode_counts.items():\n",
    "        print(f\"  {mode}: {count:,} records\")\n",
    "\n",
    "if 'country_description' in df_clean.columns:\n",
    "    print(\"\\nTop 10 countries by record count:\")\n",
    "    country_counts = df_clean['country_description'].value_counts().head(10)\n",
    "    for country, count in country_counts.items():\n",
    "        print(f\"  {country}: {count:,} records\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d709f703",
   "metadata": {},
   "source": [
    "## 4. Save Cleaned Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d26ba2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving cleaned data to: data/imports_2024_2025_cleaned.csv\n",
      " Cleaned dataset saved successfully!\n",
      "   File size: 4,481,579 rows × 23 columns\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned dataset\n",
    "output_path = 'data/imports_2024_2025_cleaned.csv'\n",
    "print(f\"Saving cleaned data to: {output_path}\")\n",
    "\n",
    "df_clean.to_csv(output_path, index=False)\n",
    "print(f\" Cleaned dataset saved successfully!\")\n",
    "print(f\"   File size: {len(df_clean):,} rows × {len(df_clean.columns)} columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98949dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SAMPLE OF CLEANED DATA ===\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>country_description</th>\n",
       "      <th>commodity_description</th>\n",
       "      <th>mode_description</th>\n",
       "      <th>valuefob</th>\n",
       "      <th>valuecif</th>\n",
       "      <th>weight</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>January</td>\n",
       "      <td>2024</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Rafts, inflatable</td>\n",
       "      <td>AIR</td>\n",
       "      <td>1204.37</td>\n",
       "      <td>1244.67</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>January</td>\n",
       "      <td>2024</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Saffron</td>\n",
       "      <td>SEA</td>\n",
       "      <td>58646.15</td>\n",
       "      <td>60840.25</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>416.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>January</td>\n",
       "      <td>2024</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Springs and leaves for springs, of iron or steel</td>\n",
       "      <td>AIR</td>\n",
       "      <td>4997.11</td>\n",
       "      <td>5094.51</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1204.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>January</td>\n",
       "      <td>2024</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Articulated link roller chain of iron or steel</td>\n",
       "      <td>AIR</td>\n",
       "      <td>3343.30</td>\n",
       "      <td>3468.06</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>103.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>January</td>\n",
       "      <td>2024</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Wooden framed seats, nes</td>\n",
       "      <td>SEA</td>\n",
       "      <td>15122.99</td>\n",
       "      <td>15779.34</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>43.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>February</td>\n",
       "      <td>2024</td>\n",
       "      <td>China (excludes SARs and Taiwan)</td>\n",
       "      <td>Soya sauce</td>\n",
       "      <td>SEA</td>\n",
       "      <td>29673.94</td>\n",
       "      <td>31669.19</td>\n",
       "      <td>24.18000</td>\n",
       "      <td>18600.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>February</td>\n",
       "      <td>2024</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>Safety headgear, whether or not lined or trimmed</td>\n",
       "      <td>SEA</td>\n",
       "      <td>151920.02</td>\n",
       "      <td>156097.23</td>\n",
       "      <td>2.29230</td>\n",
       "      <td>6616.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>February</td>\n",
       "      <td>2024</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>Food preparations, not elsewhere specified</td>\n",
       "      <td>SEA</td>\n",
       "      <td>557493.60</td>\n",
       "      <td>583064.65</td>\n",
       "      <td>120.75764</td>\n",
       "      <td>126936.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>February</td>\n",
       "      <td>2024</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Seats of a kind used for motor vehicles</td>\n",
       "      <td>AIR</td>\n",
       "      <td>3144.84</td>\n",
       "      <td>3712.08</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>February</td>\n",
       "      <td>2024</td>\n",
       "      <td>Myanmar</td>\n",
       "      <td>Footwear with outer soles of leather, nes</td>\n",
       "      <td>SEA</td>\n",
       "      <td>3455.28</td>\n",
       "      <td>3602.60</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>38.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      month  year               country_description  \\\n",
       "0   January  2024          United States of America   \n",
       "1   January  2024                             Spain   \n",
       "2   January  2024                           Germany   \n",
       "3   January  2024                             Japan   \n",
       "4   January  2024                           Germany   \n",
       "5  February  2024  China (excludes SARs and Taiwan)   \n",
       "6  February  2024                            Taiwan   \n",
       "7  February  2024                            Taiwan   \n",
       "8  February  2024                             Spain   \n",
       "9  February  2024                           Myanmar   \n",
       "\n",
       "                              commodity_description mode_description  \\\n",
       "0                                 Rafts, inflatable              AIR   \n",
       "1                                           Saffron              SEA   \n",
       "2  Springs and leaves for springs, of iron or steel              AIR   \n",
       "3    Articulated link roller chain of iron or steel              AIR   \n",
       "4                          Wooden framed seats, nes              SEA   \n",
       "5                                        Soya sauce              SEA   \n",
       "6  Safety headgear, whether or not lined or trimmed              SEA   \n",
       "7        Food preparations, not elsewhere specified              SEA   \n",
       "8           Seats of a kind used for motor vehicles              AIR   \n",
       "9         Footwear with outer soles of leather, nes              SEA   \n",
       "\n",
       "    valuefob   valuecif     weight   quantity  \n",
       "0    1204.37    1244.67    0.00000       2.00  \n",
       "1   58646.15   60840.25    0.00000     416.40  \n",
       "2    4997.11    5094.51    0.00000    1204.00  \n",
       "3    3343.30    3468.06    0.00000     103.73  \n",
       "4   15122.99   15779.34    0.00000      43.00  \n",
       "5   29673.94   31669.19   24.18000   18600.00  \n",
       "6  151920.02  156097.23    2.29230    6616.00  \n",
       "7  557493.60  583064.65  120.75764  126936.14  \n",
       "8    3144.84    3712.08    0.00000       1.00  \n",
       "9    3455.28    3602.60    0.00000      38.00  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display sample of cleaned data\n",
    "print(\"\\n=== SAMPLE OF CLEANED DATA ===\\n\")\n",
    "sample_cols = ['month', 'year', 'country_description', 'commodity_description', \n",
    "               'mode_description', 'valuefob', 'valuecif', 'weight', 'quantity']\n",
    "available_cols = [col for col in sample_cols if col in df_clean.columns]\n",
    "df_clean[available_cols].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0ecb86",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Data cleaning completed successfully!**\n",
    "\n",
    "### What was done:\n",
    "-  Standardized column names\n",
    "-  Converted numeric columns and handled missing/negative values\n",
    "-  Cleaned and standardized text fields\n",
    "-  Extracted date components (year, month number)\n",
    "-  Created derived features (value per tonne, insurance/freight costs)\n",
    "-  Removed duplicate records\n",
    "- Saved cleaned dataset to CSV format\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
